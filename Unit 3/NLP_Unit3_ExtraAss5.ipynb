{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXXYbo9fFZ_8"
      },
      "outputs": [],
      "source": [
        "# Lab Assignment 5: N-gram Language Model\n",
        "# •\tImplement unigram, bigram, and trigram models using NLTK.\n",
        "# •\tTrain on a small text dataset and compute probabilities of word sequences.\n",
        "# •\tUse Laplace smoothing to handle unseen words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and import required packages\n",
        "!pip install -q nltk\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk import FreqDist, word_tokenize, ConditionalFreqDist\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvbDt3NbF5xu",
        "outputId": "288d5e5c-db50-4ff1-f012-44f81559d2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define and tokenize a small corpus\n",
        "corpus = \"\"\"Natural language processing is a field of artificial intelligence.\n",
        "It focuses on the interaction between computers and humans through language.\n",
        "NLP enables computers to understand, interpret and generate human language.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(corpus.lower())\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaGuE8zoF50J",
        "outputId": "457fb6a8-ab45-4c72-87b1-5d5428867936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['natural', 'language', 'processing', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', '.', 'it', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', '.', 'nlp', 'enables', 'computers', 'to', 'understand', ',', 'interpret', 'and', 'generate', 'human', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build unigram, bigram, and trigram models\n",
        "unigrams = list(ngrams(tokens, 1))\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "\n",
        "# Frequency distributions\n",
        "unigram_freq = FreqDist(unigrams)\n",
        "bigram_freq = FreqDist(bigrams)\n",
        "trigram_freq = FreqDist(trigrams)\n",
        "\n",
        "# Vocabulary size\n",
        "V = len(set(tokens))"
      ],
      "metadata": {
        "id": "zWux9pgGF523"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define Laplace-smoothed probability functions\n",
        "def unigram_prob(w):\n",
        "    return (unigram_freq[(w,)] + 1) / (len(tokens) + V)\n",
        "\n",
        "def bigram_prob(w1, w2):\n",
        "    return (bigram_freq[(w1, w2)] + 1) / (unigram_freq[(w1,)] + V)\n",
        "\n",
        "def trigram_prob(w1, w2, w3):\n",
        "    return (trigram_freq[(w1, w2, w3)] + 1) / (bigram_freq[(w1, w2)] + V)"
      ],
      "metadata": {
        "id": "9tteMy6SF56T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Test the probabilities\n",
        "print(\"P('language') =\", unigram_prob('language'))\n",
        "print(\"P('natural'|'language') =\", bigram_prob('language', 'natural'))\n",
        "print(\"P('natural'|'language','processing') =\", trigram_prob('language', 'processing', 'natural'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Waz3Z5obGCWt",
        "outputId": "8481a1cf-968c-4bce-8f2d-d1db0c4b16e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('language') = 0.06451612903225806\n",
            "P('natural'|'language') = 0.03225806451612903\n",
            "P('natural'|'language','processing') = 0.034482758620689655\n"
          ]
        }
      ]
    }
  ]
}